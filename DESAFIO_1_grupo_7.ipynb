{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "identical-holmes",
   "metadata": {},
   "source": [
    "# Importamos librerías y cargamos la base de datos para comenzar a analizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dying-calvin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "straight-sleeve",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'properatti.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-2fa5bd61f69c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'properatti.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Unnamed: 0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\dhdsblend2021\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    686\u001b[0m     )\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dhdsblend2021\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dhdsblend2021\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 948\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dhdsblend2021\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dhdsblend2021\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2010\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'properatti.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('properatti.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-stability",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-cigarette",
   "metadata": {},
   "source": [
    " Vemos cuantas Filas y Columnas tiene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-complexity",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"cantidad de filas: \" + str(data.shape[0]))\n",
    "print(\"cantidad de columnas: \" + str(data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-footage",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-festival",
   "metadata": {},
   "source": [
    "Eliminamos columnas que sabemos que no vamos a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-insured",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"image_thumbnail\", \"properati_url\", \"expenses\", \"floor\"], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-needle",
   "metadata": {},
   "source": [
    "### Obtenemos los porcentajes de datos faltantes de cada columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-administrator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_na(df, zeros=False):\n",
    "    miss      = df.isnull().sum(axis=0)\n",
    "    miss_prop = miss / len(df)\n",
    "    freq = pd.concat([miss, miss_prop], axis=1)\n",
    "    freq.columns = ['total', 'proporcion']\n",
    "    return freq if zeros else freq[freq['total'] > 0].sort_values(by='proporcion',ascending=False)\n",
    "\n",
    "freq_na(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_nulos(df):\n",
    "    \n",
    "    nulos = df.isnull().sum() / len(df)\n",
    "    nulos = nulos[nulos > 0]\n",
    "    nulos.sort_values(inplace=True)\n",
    "    \n",
    "    nulos = nulos.to_frame()\n",
    "    nulos.columns = ['total']\n",
    "    nulos.index.names = ['variable']\n",
    "    nulos['variable'] = nulos.index\n",
    "    # ploteo\n",
    "    sns.set(style=\"whitegrid\", color_codes=True)\n",
    "    sns.barplot(x='variable', y='total', data=nulos)\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.show()\n",
    "mostrar_nulos(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-determination",
   "metadata": {},
   "source": [
    "CONCLUSIÓN DE LA OBSERVACIÓN INICIAL:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-project",
   "metadata": {},
   "source": [
    "El DataSet posee algunas columnas con muchos valores faltantes, posibles duplicados o posibles datos no confiables.\n",
    "\n",
    "Las columnas o datos centrales del análisis que realizaremos son aquellos que nos indiquen:\n",
    "\n",
    "a) ubicación de las observaciones\n",
    "\n",
    "b) precio x M2\n",
    "\n",
    "c) las variables de las cuales dependan las mismas (como ser tipo de propiedad, amenities, garage).\n",
    "\n",
    "Por lo antes dicho, en este momento sólo nos limitaremos a realizar un drop de las observaciones duplicadas que puedan existir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-belle",
   "metadata": {},
   "source": [
    "##### Evaluando data para ver si hay datos duplicados incluyendo la mayor cantidad de columnas que logicamente deban coincidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-margin",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_duplicates_mask = data.duplicated(subset=[\"place_name\", \"country_name\", \"description\", \"title\", \"lat-lon\", \"state_name\", \"price_aprox_usd\"], keep=\"first\")\n",
    "print(\"registros duplicados en data: \", any(data_duplicates_mask))\n",
    "print(\"cantidad de registros duplicados en data: \", data_duplicates_mask.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= data.drop_duplicates(subset=[\"place_name\", \"country_name\", \"description\", \"title\", \"lat-lon\", \"state_name\", \"price_aprox_usd\"], keep=\"first\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-delta",
   "metadata": {},
   "source": [
    "### ANÁLISIS DE COLUMNAS DE 0 A 9 - UBICACION DE LAS OBSERVACIONES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-morris",
   "metadata": {},
   "source": [
    "##### Columna operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como vemos posee la totalidad de valores sell y sin vacíos, por lo que no agregaría valor. Atacaremos el Drop de columnas más adelante.\n",
    "operation_group = data.groupby('operation').country_name.count()\n",
    "operation_group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-graphic",
   "metadata": {},
   "source": [
    "##### Columna property type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como vemos posee la totalidad de valores completos y nos será de mucha importancia para analizar los valores por tipo de propiedad.\n",
    "property_type_group = data.groupby('property_type').property_type.count()\n",
    "property_type_group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-hundred",
   "metadata": {},
   "source": [
    "Todos los valores estan son \"PH\", \"apartment\", \"house\" y \"store\". Sin valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciudades = data.groupby('place_name').place_name.count()\n",
    "ciudades_ordenadas = ciudades.sort_values(ascending=False)\n",
    "ciudades_ordenadas.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-video",
   "metadata": {},
   "source": [
    "##### Columna place_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-austin",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.place_name.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepting-richardson",
   "metadata": {},
   "source": [
    "Contiene 23 valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-sustainability",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_name_nulos = data.loc[data.place_name.isnull(), :]\n",
    "place_name_nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-notification",
   "metadata": {},
   "source": [
    "Todos los valores nulos son de Tigre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.place_name.fillna('Tigre', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-lindsay",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.place_name.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.place_name[6489]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-convert",
   "metadata": {},
   "source": [
    "Reemplazo de todos los valores nulos por \"Tigre\", ya que en place_with_parent_names contiene en todos 'Tigre' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-wiring",
   "metadata": {},
   "source": [
    "##### Columna country_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como vemos posee la totalidad de valores Argentina, por lo que no agregaría valor. Atacaremos el Drop de columnas más adelante.\n",
    "country_name_group = data.groupby('country_name').country_name.count()\n",
    "country_name_group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-timing",
   "metadata": {},
   "source": [
    "Todos los valores son \"Argentina\" y no hay vacios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-vulnerability",
   "metadata": {},
   "source": [
    "##### Columna state_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_name_group = data.groupby('state_name').state_name.count()\n",
    "state_name_group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-marker",
   "metadata": {},
   "source": [
    "Ningun valor nulo. Algunas provincias poseen pocas observaciones, cosa que analizaremos más adelante"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-algeria",
   "metadata": {},
   "source": [
    "##### Columna place_with_parent_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizamos esta columna que como vemos abajo tiene separado por una barra vertical cada ubicación de más general a menos general.\n",
    "# Parte del país, luego va a la provincia, luego la localidad y el barrio en algunos casos.\n",
    "\n",
    "place_with_parent_names_group = data.groupby('place_with_parent_names').place_with_parent_names.count()\n",
    "place_with_parent_names_group.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-interpretation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Contiene\", len(place_with_parent_names_group.index),\"valores distintos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separamos la columna por la barra verical para poder aperturarlo.\n",
    "\n",
    "placestr=data.place_with_parent_names.str\n",
    "placeseparado = placestr.split('|', expand=True)\n",
    "placeseparado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombramos las columnas del nuevo DF para luego comparar. Tener en cuenta que place_name tiene la mínima expresión de la ubicación.\n",
    "\n",
    "placeseparado.rename(columns={1:'country_name_nuevo', 2:'state_name_nuevo', 3:'place_name_nuevo1', 4:'place_name_nuevo2'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "placeseparado.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparamos si coinciden el país que extrajimos de la columna con country_name. Está ok\n",
    "controlpaises = data['country_name'] == placeseparado['country_name_nuevo']\n",
    "controlpaises.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparamos ahora si coincide la provincia y está ok.\n",
    "controlprovincias = data['state_name'] == placeseparado['state_name_nuevo']\n",
    "controlprovincias.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-element",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tratamos de analizar ahora place_name.\n",
    "# vemos que la columna 6 del nuevo DF son vacios asique la podemos eliminar\n",
    "placeseparado[6][placeseparado[6].notnull()].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-working",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vemos que la columna 5 del nuevo DF la mayoría son vacíos y algunos son Barrios.\n",
    "a = placeseparado[5][placeseparado[5].notnull()].value_counts()\n",
    "print(a)\n",
    "\n",
    "# transformamos en NaN los vacíos\n",
    "placeseparado[5] = placeseparado[5].apply(lambda x: np.NaN if x=='' else x)\n",
    "a = placeseparado[5][placeseparado[5].notnull()].value_counts()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.place_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-company",
   "metadata": {},
   "outputs": [],
   "source": [
    "# De esta columna 5 del nuevo DF se puede ver que son barrios cerrados y coinciden con el data frame original.\n",
    "b = data.place_name[placeseparado[5].notnull()]\n",
    "print(b)\n",
    "\n",
    "c = placeseparado[5][placeseparado[5].notnull()] == b\n",
    "print(c.value_counts())\n",
    "\n",
    "# Acá vemos que la totalidad de esos Barrios corresponden a Nordelta, por lo que los sacamos del Data Frame original\n",
    "# y reemplazamos todos esos valores por Nordelta para poder analizarlos mejor\n",
    "d = placeseparado['place_name_nuevo2'][placeseparado[5].notnull()]\n",
    "print(d.value_counts())\n",
    "\n",
    "data.place_name[placeseparado[5].notnull()] == d\n",
    "data.place_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-footage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vemos que la columna 4 que llamamos place_name_nuevo2 del nuevo DF la mayoría son vacíos.\n",
    "a = placeseparado.place_name_nuevo2[placeseparado['place_name_nuevo2'].notnull()].value_counts()\n",
    "print(a)\n",
    "\n",
    "# transformamos en NaN los vacíos\n",
    "placeseparado.place_name_nuevo2 = placeseparado.place_name_nuevo2.apply(lambda x: np.NaN if x=='' else x)\n",
    "a = placeseparado.place_name_nuevo2[placeseparado['place_name_nuevo2'].notnull()].value_counts()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-connectivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# De esta columna 4 del nuevo DF se puede ver que todo coincide con place_name.\n",
    "b = data.place_name[placeseparado['place_name_nuevo2'].notnull()]\n",
    "print(b)\n",
    "\n",
    "c = placeseparado.place_name_nuevo2[placeseparado['place_name_nuevo2'].notnull()] == b\n",
    "print(c.value_counts())\n",
    "\n",
    "d = placeseparado['place_name_nuevo1'][placeseparado['place_name_nuevo2'].notnull()]\n",
    "print(d.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-kingston",
   "metadata": {},
   "source": [
    "CONCLUSIÓN DEL ANALISIS DE LAS COLUMNAS DE UBICACIÓN:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-height",
   "metadata": {},
   "source": [
    "El DataSet posee observaciones repartidas poro todo el país, y antes de sacar una conclusión, vamos a analizar el peso real de la cantidad de observaciones en cada territorio.\n",
    "\n",
    "Como vemos abajo, son 28 las zonas provinciales (incluye la provincia de Bs As separada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-accuracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos distribución por provincia\n",
    "distr_x_pcia = data['state_name'].value_counts()\n",
    "print(distr_x_pcia.count())\n",
    "distr_x_pcia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-kruger",
   "metadata": {},
   "source": [
    "Vamos a listar el tamaño en KMS2 de las distintas provincias (o zonas) de las cuales tenemos datos y a calcular la cantidad de operaciones por KM2 que tenemos en cada una\n",
    "\n",
    "#Capital Federal                 202\n",
    "#Bs.As. G.B.A. Zona Norte        1427\n",
    "#Bs.As. G.B.A. Zona Sur          1207\n",
    "#Córdoba                         165321\n",
    "#Santa Fe                        133007\n",
    "#Buenos Aires Costa Atlántica    1280\n",
    "#Bs.As. G.B.A. Zona Oeste        1046\n",
    "#Buenos Aires Interior           302611\n",
    "#Río Negro                       203013\n",
    "#Neuquén                         94078\n",
    "#Mendoza                         148827\n",
    "#Tucumán                         22524\n",
    "#Corrientes                      88199\n",
    "#Misiones                        29801\n",
    "#Entre Ríos                      78781\n",
    "#Salta                           155488\n",
    "#Chubut                          224686\n",
    "#San Luis                        76748\n",
    "#La Pampa                        143440\n",
    "#Formosa                         72066\n",
    "#Chaco                           99633\n",
    "#San Juan                        89651\n",
    "#Tierra Del Fuego                21478\n",
    "#Catamarca                       102602\n",
    "#Jujuy                           53219\n",
    "#Santa Cruz                      243943\n",
    "#Santiago Del Estero             136351\n",
    "#La Rioja                        89680"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "tamañokms = pd.Series([202, 1427, 1207, 165321, 133007, 1280, 1046, 302611, 203013, 94078, 148827, 22524, 88199, 29801, 78781, 155488, 224686, 76748, 143440, 72066, 99633, 89651, 21478, 102602, 53219, 243943, 136351, 89680])\n",
    "print(distr_x_pcia.shape)\n",
    "print(tamañokms.shape)\n",
    "print(distr_x_pcia.dtype)\n",
    "print(tamañokms.dtype)\n",
    "\n",
    "print(\"Capital Federal - Operaciones por KM2 -: \", (distr_x_pcia[0]/tamañokms[0]).round(2))\n",
    "print(\"Bs.As. G.B.A. Zona Norte - Operaciones por KM2 -: \", (distr_x_pcia[1]/tamañokms[1]).round(2))\n",
    "print(\"Bs.As. G.B.A. Zona Sur - Operaciones por KM2 -: \", (distr_x_pcia[2]/tamañokms[2]).round(2))\n",
    "print(\"Córdoba - Operaciones por KM2 -: \", (distr_x_pcia[3]/tamañokms[3]).round(2))\n",
    "print(\"Santa Fe - Operaciones por KM2 -: \", (distr_x_pcia[4]/tamañokms[4]).round(2))\n",
    "print(\"Buenos Aires Costa Atlántica - Operaciones por KM2 -: \", (distr_x_pcia[5]/tamañokms[5]).round(2))\n",
    "print(\"Bs.As. G.B.A. Zona Oeste - Operaciones por KM2 -: \", (distr_x_pcia[6]/tamañokms[6]).round(2))\n",
    "print(\"Buenos Aires Interior - Operaciones por KM2 -: \", (distr_x_pcia[7]/tamañokms[7]).round(2))\n",
    "print(\"Río Negro - Operaciones por KM2 -: \", (distr_x_pcia[8]/tamañokms[8]).round(2))\n",
    "print(\"Neuquen - Operaciones por KM2 -: \", (distr_x_pcia[9]/tamañokms[9]).round(2))\n",
    "print(\"Mendoza - Operaciones por KM2 -: \", (distr_x_pcia[10]/tamañokms[10]).round(2))\n",
    "print(\"Tucuman - Operaciones por KM2 -: \", (distr_x_pcia[11]/tamañokms[11]).round(2))\n",
    "print(\"Corrientes - Operaciones por KM2 -: \", (distr_x_pcia[12]/tamañokms[12]).round(2))\n",
    "print(\"Misiones - Operaciones por KM2 -: \", (distr_x_pcia[13]/tamañokms[13]).round(2))\n",
    "print(\"Entre Ríos - Operaciones por KM2 -: \", (distr_x_pcia[14]/tamañokms[14]).round(2))\n",
    "print(\"Salta - Operaciones por KM2 -: \", (distr_x_pcia[15]/tamañokms[15]).round(2))\n",
    "print(\"Chubut - Operaciones por KM2 -: \", (distr_x_pcia[16]/tamañokms[16]).round(2))\n",
    "print(\"San Luis - Operaciones por KM2 -: \", (distr_x_pcia[17]/tamañokms[17]).round(2))\n",
    "print(\"La Pampa - Operaciones por KM2 -: \", (distr_x_pcia[18]/tamañokms[18]).round(2))\n",
    "print(\"Formosa - Operaciones por KM2 -: \", (distr_x_pcia[19]/tamañokms[19]).round(2))\n",
    "print(\"Chaco - Operaciones por KM2 -: \", (distr_x_pcia[20]/tamañokms[20]).round(2))\n",
    "print(\"San Juan - Operaciones por KM2 -: \", (distr_x_pcia[21]/tamañokms[21]).round(2))\n",
    "print(\"Tierra del Fuego - Operaciones por KM2 -: \", (distr_x_pcia[22]/tamañokms[22]).round(2))\n",
    "print(\"Catamarca - Operaciones por KM2 -: \", (distr_x_pcia[23]/tamañokms[23]).round(2))\n",
    "print(\"Jujuy - Operaciones por KM2 -: \", (distr_x_pcia[24]/tamañokms[24]).round(2))\n",
    "print(\"Santa Cruz - Operaciones por KM2 -: \", (distr_x_pcia[25]/tamañokms[25]).round(2))\n",
    "print(\"Santiago del Estero - Operaciones por KM2 -: \", (distr_x_pcia[26]/tamañokms[26]).round(2))\n",
    "print(\"La Rioja - Operaciones por KM2 -: \", (distr_x_pcia[27]/tamañokms[27]).round(2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-skirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos que dentro de Capital Federal, 1027 valores no tienen definición de Localidad, por lo que estas tendremos que buscarlas por el lado de lat-lon.\n",
    "# Por otro lado vemos que Palermo está divido por zonas, en esta primera iteración lo dejaremos así.\n",
    "Control = data.place_name[data['state_name'] == 'Capital Federal']\n",
    "print(Control.value_counts())\n",
    "print(Control.shape)\n",
    "Control.value_counts().head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-criticism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos que dentro de GBA Zona Norte, 221 valores no tienen definición de Localidad, por lo que al no ser significativas las eliminaremos.\n",
    "Control = data.place_name[data['state_name'] == 'Bs.As. G.B.A. Zona Norte']\n",
    "print(Control.value_counts())\n",
    "print(Control.shape)\n",
    "Control.value_counts().head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-feelings",
   "metadata": {},
   "source": [
    "CONCLUSIÓN DEL ANALISIS DE LAS COLUMNAS DE UBICACIÓN: Si bien es correcto que en el Interior existe mucho terreno con poca densidad poblacional y podríamos analizar ciudades puntuales como Santa Fe, Rosario o Córdoba, en esta primera iteración vamos a limitar el análisis a las 2 zonas con mayor cantidad de operaciones por KM2 --> Capital Federal y GBA Zona Norte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-james",
   "metadata": {},
   "source": [
    "CREAMOS UN DATAFRAME EN EL QUE SÓLO CONTIENE A CABA Y GBA ZONA NORTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-sally",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = data.loc[:, 'state_name'].isin(['Capital Federal','Bs.As. G.B.A. Zona Norte'])\n",
    "data = data.loc[cf]\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-laugh",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_split = data.place_with_parent_names.str.split('|', expand=True).rename({1:'pais', 2:'provincia', 3:'localidad', 4:'barrio'}, axis=1).drop([0,5,6], axis=1)\n",
    "place_split['geonames_id'] = data['geonames_id']\n",
    "place_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-processor",
   "metadata": {},
   "outputs": [],
   "source": [
    "localidades = place_split.groupby('localidad').localidad.count().sort_values(ascending=False)\n",
    "localidades.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_split['localidad'] = place_split['localidad'].apply(lambda x: np.NaN if x=='' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-substitute",
   "metadata": {},
   "outputs": [],
   "source": [
    "mascara_sin_localidad = place_split.localidad.isnull()\n",
    "mascara_sin_localidad.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "mascara_sin_localidad = place_split.localidad.isnull()\n",
    "geonames_id_sin_localidad = place_split[mascara_sin_localidad].groupby('geonames_id').geonames_id.count().sort_values(ascending=False)\n",
    "geonames_id_sin_localidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-surface",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeticiones_geonames_id_sin_localidad = place_split[place_split.geonames_id == 3433955.0].groupby('geonames_id').geonames_id.count().sort_values(ascending=False)\n",
    "repeticiones_geonames_id_sin_localidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeticiones_geonames_id_sin_localidad = place_split[place_split.geonames_id == 3435907.0].groupby('geonames_id').geonames_id.count().sort_values(ascending=False)\n",
    "repeticiones_geonames_id_sin_localidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-yield",
   "metadata": {},
   "source": [
    "Podemos ver que los dos geonames_id que nos faltan en ningun registro tienen imputado la localidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-florence",
   "metadata": {},
   "outputs": [],
   "source": [
    "mascara_capital = place_split.provincia == 'Capital Federal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-portuguese",
   "metadata": {},
   "outputs": [],
   "source": [
    "mascara_bs_as_nor = place_split.provincia == 'Bs.As. G.B.A. Zona Norte'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-presence",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lon_sin_localidad_capital = data[mascara_sin_localidad].groupby('lat-lon').lat.count().sort_values(ascending=False)\n",
    "lat_lon_sin_localidad_capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-bristol",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hay\", lat_lon_sin_localidad_capital.sum(), \"operaciones en Capital Federal sin localidad que tienen imputado lat-lon. Se repiten asi que no son datos muy fiables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-absorption",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lon_sin_localidad_bs_as_nor = data[mascara_sin_localidad&mascara_bs_as_nor].groupby('lat').lat.count().sort_values(ascending=False)\n",
    "lat_lon_sin_localidad_bs_as_nor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hay\", lat_lon_sin_localidad_bs_as_nor.sum(), \"operaciones en Bs.As. G.B.A. Zona Norte sin localidad que tienen imputado lat-lon.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-batman",
   "metadata": {},
   "source": [
    "### ANÁLISIS DE COLUMNAS DE 10 A 17 - PRECIO POR METRO CUADRADO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-fifteen",
   "metadata": {},
   "source": [
    "#### ANÁLISIS DE PRECIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-frequency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a analizar puntualmente la columna price\n",
    "# Vemos que es de tipo flotante y posee en principio los valores a los que se realizó cada operación. \n",
    "data['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-idaho",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si vemos la columna siguiente (tipo Str), posee la moneda en la que se realizó la operación.\n",
    "data['currency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-peoples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos que de los 54887 valores, 3180 son nulos para la columna de price\n",
    "data.price.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos también que 3180 son nulos para la columna de currency\n",
    "data.currency.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a asegurarnos que los no nulos coincidan entre las columnas\n",
    "price_nulo_bool = data.price.isnull()\n",
    "currency_nulo_bool = data.currency.isnull()\n",
    "precio_sin_currency = price_nulo_bool == currency_nulo_bool\n",
    "precio_sin_currency.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-advertiser",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En el DF original había valores 0 en la columna Price, por lo que vamos a corroborar que ahora no exista ninguno.\n",
    "\n",
    "precios0 = data['price'] == 0\n",
    "precios0.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-decrease",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora vamos a ver las otras columnas si también coinciden\n",
    "data.price_aprox_local_currency.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.price_aprox_usd.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-antenna",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nos aseguramos que los valores de estas 3 columnas coincidan en los nulos\n",
    "price_nulo1_bool = data.price_aprox_local_currency.isnull()\n",
    "price_nulo2_bool = data.price_aprox_usd.isnull()\n",
    "price_nulo_bool = data.price.isnull()\n",
    "precio_control1 = price_nulo1_bool == price_nulo2_bool\n",
    "precio_control2 = price_nulo1_bool == price_nulo_bool\n",
    "a = precio_control1.value_counts()\n",
    "print(a)\n",
    "b = precio_control2.value_counts()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-cream",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos que en la columna currency, actualmente hay 3 tipos de monedas, por lo que analizaremos 1 por 1 (el UYU fue eliminado por zonas, pero el tipo de cambio también era lógico).\n",
    "data['currency'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos los valores de moneda PEN (Sol Peruano)\n",
    "CurrencyPEN = data.loc[:, \"currency\"] == \"PEN\"\n",
    "dfCurrencyPEN = data.loc[CurrencyPEN]\n",
    "dfCurrencyPEN.loc[:, ['place_name','country_name', 'state_name', 'price', 'currency', 'price_aprox_local_currency', 'price_aprox_usd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-arrangement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, es logico el tipo de cambio del PEN por lo que lo dejamos así\n",
    "print(117139/380000)\n",
    "print(292848/950000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-wrestling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos los valores de moneda ARS (Peso Argentino)\n",
    "CurrencyARS = data.loc[:, \"currency\"] == \"ARS\"\n",
    "dfCurrencyARS = data.loc[CurrencyARS]\n",
    "dfCurrencyARS.loc[:, ['place_name','country_name', 'state_name', 'price', 'currency', 'price_aprox_local_currency', 'price_aprox_usd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-murray",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos que entre Price y price_aprox_local_currency no son exactamente los mismos porque seguramente la de local toma un promedio\n",
    "# del tipo de cambio, pero al menos la división entre una y otra columna debería tender a 1\n",
    "controlpricears = dfCurrencyARS.price / dfCurrencyARS.price_aprox_local_currency\n",
    "may = controlpricears > 1.05\n",
    "men = controlpricears < 0.95\n",
    "print(may.value_counts())\n",
    "men.value_counts()\n",
    "# Vemos que la diferencia en todos los casos está entre 5% mayor o menor, asique estaría ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-environment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora revisaremos el Tipo de Cambio Usd/Ars\n",
    "controltipodecambio = dfCurrencyARS.price / dfCurrencyARS.price_aprox_usd\n",
    "print(controltipodecambio.max())\n",
    "print(controltipodecambio.min())\n",
    "tipo_cambio_ars_promedio = controltipodecambio.mean()\n",
    "tipo_cambio_ars_promedio\n",
    "# No tenemos las fechas de las operaciones, pero la información se corresponde con tipos de cambio del año 2017 lo que es posible\n",
    "# Por otro lado no existen tipos de cambio fuera de lo común, son todos lógicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-universe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos los valores de moneda USD (Dolar Americano)\n",
    "CurrencyUSD = data.loc[:, \"currency\"] == \"USD\"\n",
    "dfCurrencyUSD = data.loc[CurrencyUSD]\n",
    "dfCurrencyUSD.loc[:, ['place_name','country_name', 'state_name', 'price', 'currency', 'price_aprox_local_currency', 'price_aprox_usd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-organ",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debería coincidir la columna Price con price_aprox_usd asique vamos a controlarlo\n",
    "controlvaloresenusd = dfCurrencyUSD.price - dfCurrencyUSD.price_aprox_usd\n",
    "controlvaloresenusd.value_counts()\n",
    "# Vemos que todos coinciden asique perfecto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-endorsement",
   "metadata": {},
   "source": [
    "CONCLUSIÓN INICIAL PRECIOS: Consideramos que los valores incluidos en las columnas analizadas son lógicos y sólidos para ahora avanzar con la búsqueda de datos faltantes u Outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-balloon",
   "metadata": {},
   "source": [
    "Búsqueda de valores faltantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-geneva",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recordemos que esta columna tiene 54887 datos de los cuales 3180 datos son NaN (5,79%)\n",
    "is_null_result = data.price_aprox_usd.isnull()\n",
    "is_notnull_result = data.price_aprox_usd.notnull()\n",
    "totaldata=data.price_aprox_usd.shape[0]\n",
    "print(totaldata)\n",
    "cant_notnull = is_notnull_result.sum()\n",
    "print(cant_notnull)\n",
    "cant_nulls = is_null_result.sum()\n",
    "print(cant_nulls)\n",
    "print(cant_nulls/totaldata*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-coupon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# de una observación visual podemos ver que en la columna \"Title\" podemos sacar valores de publicacion que si bien pueden ser distintos\n",
    "# al valor de la operación final, no deberían distar demasiado de esta\n",
    "\n",
    "#para los valores dolares entre 1000 y 999999\n",
    "import re\n",
    "pattern_dol = \"(D *)(?P<Dolares1>[1-9]\\d\\d*).(?P<Dolares2>\\d\\d\\d)\"\n",
    "pattern_dol_regex =  re.compile(pattern_dol)\n",
    "\n",
    "resultado_dol = data.title.apply(lambda x: pattern_dol_regex.search(x))\n",
    "dol_match1 = resultado_dol.apply(lambda x: x if x is None else x.group(\"Dolares1\"))\n",
    "dol_match2 = resultado_dol.apply(lambda x: x if x is None else x.group(\"Dolares2\"))\n",
    "dol_match = dol_match1 + dol_match2\n",
    "\n",
    "dol_match_fill = dol_match.fillna(0)\n",
    "dol_match_fill_numeric = dol_match_fill.astype(float)\n",
    "\n",
    "dol_match_fill_numeric.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#para los valores dolares entre mayores a 999999\n",
    "import re\n",
    "pattern_dol = \"(D *)(?P<Dolares1>[1-9]\\d*).(?P<Dolares2>\\d\\d\\d).(?P<Dolares3>\\d\\d\\d)\"\n",
    "pattern_dol_regex =  re.compile(pattern_dol)\n",
    "\n",
    "resultado_dol = data.title.apply(lambda x: pattern_dol_regex.search(x))\n",
    "dol_match1 = resultado_dol.apply(lambda x: x if x is None else x.group(\"Dolares1\"))\n",
    "dol_match2 = resultado_dol.apply(lambda x: x if x is None else x.group(\"Dolares2\"))\n",
    "dol_match3 = resultado_dol.apply(lambda x: x if x is None else x.group(\"Dolares3\"))\n",
    "dol_match = dol_match1 + dol_match2 + dol_match3\n",
    "\n",
    "dol_match_fill = dol_match.fillna(0)\n",
    "dol_match_fill_numericmillon = dol_match_fill.astype(float)\n",
    "\n",
    "dol_match_fill_numericmillon.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "#para los valores pesos mayores a 999999 y luego lo pasamos a Dolares según el promedio del T/C\n",
    "import re\n",
    "pattern_pes = \"[$] (?P<Pesos1>[1-9]\\d*).(?P<Pesos2>\\d\\d\\d).(?P<Pesos3>\\d\\d\\d)\"\n",
    "pattern_pes_regex =  re.compile(pattern_pes)\n",
    "\n",
    "resultado_pes = data.title.apply(lambda x: pattern_pes_regex.search(x))\n",
    "pes_match1 = resultado_pes.apply(lambda x: x if x is None else x.group(\"Pesos1\"))\n",
    "pes_match2 = resultado_pes.apply(lambda x: x if x is None else x.group(\"Pesos2\"))\n",
    "pes_match3 = resultado_pes.apply(lambda x: x if x is None else x.group(\"Pesos3\"))\n",
    "pes_match = pes_match1 + pes_match2 + pes_match3\n",
    "\n",
    "pes_match_fill = pes_match.fillna(0)\n",
    "pes_match_fill_numericmillon = pes_match_fill.astype(float)\n",
    "\n",
    "pes_match_fill_numericmillonDOLAR = pes_match_fill_numericmillon / tipo_cambio_ars_promedio\n",
    "pes_match_fill_numericmillonDOLAR.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-raleigh",
   "metadata": {},
   "outputs": [],
   "source": [
    "#para los valores pesos menosres a 999999 y luego lo pasamos a Dolares según el promedio del T/C\n",
    "import re\n",
    "pattern_pes = \"[$] (?P<Pesos1>[1-9]\\d\\d\\d*).(?P<Pesos2>\\d\\d\\d)\"\n",
    "pattern_pes_regex =  re.compile(pattern_pes)\n",
    "\n",
    "resultado_pes = data.title.apply(lambda x: pattern_pes_regex.search(x))\n",
    "pes_match1 = resultado_pes.apply(lambda x: x if x is None else x.group(\"Pesos1\"))\n",
    "pes_match2 = resultado_pes.apply(lambda x: x if x is None else x.group(\"Pesos2\"))\n",
    "pes_match = pes_match1 + pes_match2\n",
    "\n",
    "pes_match_fill = pes_match.fillna(0)\n",
    "pes_match_fill_numericmenosmillon = pes_match_fill.astype(float)\n",
    "\n",
    "pes_match_fill_numericmenosmillonDOLAR = pes_match_fill_numericmenosmillon / tipo_cambio_ars_promedio\n",
    "pes_match_fill_numericmenosmillonDOLAR.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora en la variable \"dol_match_fill_numeric\" están los dolares menores a 999.999 Usd\n",
    "#Ahora en la variable \"dol_match_fill_numericmillon\" están los dolares mayores a 999.999 Usd\n",
    "#Ahora en la variable \"pes_match_fill_numericmillonDOLAR\" están expresados en Usd los pesos mayores a 999.999 $\n",
    "#Ahora en la variable \"pes_match_fill_numericmenosmillonDOLAR\" están expresados en Usd los pesos menores a 999.999 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-saskatchewan",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.price_aprox_usd.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a cambiar en la columna Precio todos los NaN por los valores de dol_match_fill_numeric, tener en cuenta que quedan 0 NaN y les\n",
    "# pone 0.\n",
    "data.price_aprox_usd.fillna(value=dol_match_fill_numeric, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-leisure",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data.price_aprox_usd.isnull().sum()\n",
    "\n",
    "data.price_aprox_usd.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.price_aprox_usd = data.price_aprox_usd.apply(lambda x: np.NaN if x==0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-mountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.price_aprox_usd.fillna(value=dol_match_fill_numericmillon, inplace=True)\n",
    "data.price_aprox_usd.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.price_aprox_usd = data.price_aprox_usd.apply(lambda x: np.NaN if x==0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-bangladesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.price_aprox_usd.fillna(value=pes_match_fill_numericmillonDOLAR, inplace=True)\n",
    "data.price_aprox_usd.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-workplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.price_aprox_usd = data.price_aprox_usd.apply(lambda x: np.NaN if x==0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-elizabeth",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.price_aprox_usd.fillna(value=pes_match_fill_numericmenosmillonDOLAR, inplace=True)\n",
    "data.price_aprox_usd.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-syndicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.price_aprox_usd = data.price_aprox_usd.apply(lambda x: np.NaN if x==0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.price_aprox_usd.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-contest",
   "metadata": {},
   "source": [
    "Con la búsqueda de valores en Title, pasamos de 3180 valores nulos a 2478."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-cycle",
   "metadata": {},
   "source": [
    "#### ANÁLISIS DE METROS 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_pattern = \"\\s(?P<metros>\\d{0,3}?[.]?\\d*)\\s?(?P<sufijo>m2|M2|metros|mts|m²)\"\n",
    "m2_regex =  re.compile(m2_pattern)\n",
    "m2_match = data.description.apply(lambda x: x if x is np.NaN else m2_regex.search(x))\n",
    "m2_match_mask = m2_match.notnull()\n",
    "data.loc[m2_match_mask, \"M2\"] = m2_match[m2_match_mask].apply(lambda x: x.group(\"metros\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"M2\"].replace(to_replace = \"\", value= np.NaN, inplace = True)\n",
    "data[\"M2\"] = data[\"M2\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-lancaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "#si solo tengo valor en M2, lo llevo a metros\n",
    "data['metros1'] = data[(data['surface_total_in_m2'].isnull()) & (data['surface_covered_in_m2'].isnull()) & (data['M2'].notnull())][\"M2\"]\n",
    "#si tengo valor en surface_covered_in_m2 lo llevo a metros\n",
    "data['metros2'] = data[(data['surface_total_in_m2'].isnull()) & (data['surface_covered_in_m2'].notnull())]['surface_covered_in_m2']\n",
    "#si tengo valor en surface_total_in_m2 lo llevo a metros\n",
    "data['metros3'] = data[(data['surface_total_in_m2'].notnull()) & (data['surface_covered_in_m2'].isnull())]['surface_total_in_m2']\n",
    "#si tengo covered y total, tomo total\n",
    "data['metros4'] = data[(data['surface_total_in_m2'].notnull()) & (data['surface_covered_in_m2'].notnull())]['surface_total_in_m2'] \n",
    "\n",
    "data[\"metros1\"].fillna(0, inplace=True)\n",
    "data[\"metros2\"].fillna(0, inplace=True)\n",
    "data[\"metros3\"].fillna(0, inplace=True)\n",
    "data[\"metros4\"].fillna(0, inplace=True)\n",
    "\n",
    "#creo nueva columna de m2 calculados donde sumo los metros de cada condicion.\n",
    "data['m2_calculated'] = data.apply(lambda x: x['metros1'] + x['metros2'] + x[\"metros3\"] + x[\"metros4\"], axis=1)\n",
    "data[\"m2_calculated\"].replace(to_replace = 0, value= np.NaN, inplace = True)\n",
    "\n",
    "#df.drop([\"metros1\", \"metros2\", \"metros3\", \"metros4\", \"M2\", \"surface_covered_in_m2\", \"surface_total_in_m2\"], axis=1, inplace = True)\n",
    "# Sabemos que algunos datos recuperados son erroneos como por ejemplo \"a tantos metros de tal lugar\", pero al ser outliers, se filtrarán a posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-surgeon",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cantidad surface_total_in_m2 null en df inicial:', data[\"surface_total_in_m2\"].isnull().sum())\n",
    "print('Cantidad surface_covered_in_m2 null en df inicial:', data[\"surface_covered_in_m2\"].isnull().sum())\n",
    "print('Cantidad m2_calculated null en df trabajado:', data[\"m2_calculated\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-passenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EN ESTE MOMENTO TENEMOS LA COLUMNA \"price_aprox_usd\" CON LOS PRECIOS EN USD DEFINITIVOS\n",
    "# Y TENEMOS LA COLUMNA \"m2_calculated\" CON LOS M2 DEFINITIVOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-keyboard",
   "metadata": {},
   "source": [
    "#### CREAMOS COLUMNA DE USD/M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos columna con los datos de Usd/M2 según las columnas creadas por nosotros\n",
    "data[\"USDxM2\"] = data[\"price_aprox_usd\"]/data[\"m2_calculated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-second",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cantidad total datos USD:', data[\"price_aprox_usd\"].shape[0])\n",
    "print('Cantidad nulos datos USD:', data[\"price_aprox_usd\"].isnull().sum())\n",
    "print('Cantidad total datos M2:', data[\"m2_calculated\"].shape[0])\n",
    "print('Cantidad nulos datos M2:', data[\"m2_calculated\"].isnull().sum())\n",
    "print('Cantidad total datos USDxM2:', data[\"USDxM2\"].shape[0])\n",
    "print('Cantidad nulos datos USDxM2:', data[\"USDxM2\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-compromise",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora procedemos a eliminar todas las filas donde no tenemos Usd/m2 ya que es un dato clave que no vemos conveniente inferir.\n",
    "print(data.shape)\n",
    "data = data.dropna(subset=['USDxM2'], axis = 0) #meter implace para dejarlo en la base.\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-floor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos la existencia de Outliers\n",
    "sns.set_style('darkgrid')\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.boxplot(data=data.state_name[data.property_type=='house'], x=data.state_name[data.property_type=='house'], y=data.USDxM2)\n",
    "\n",
    "plt.xlabel(\"Ciudades\"); plt.ylabel(\"Usd/M2\");plt.title(\"Distribución Dólares por M2 por Ciudad\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-times",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_agrupado = data.groupby(['property_type', 'state_name'])\n",
    "data_agrupado.describe()['USDxM2'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-ferry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBIDO A QUE ESTAMOS FILTRANDO DESDE STATE NAME EN VEZ DE DESDE LA LOCALIDAD, ACA ELEGIMOS DEL 25%, CUANTAS MUESTRAS MENORES VAMOS A TOMAR Y DEL 75% CUANTAS MUESTRAS MAYORES\n",
    "MEN = 0.5\n",
    "MAY = 1.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-athens",
   "metadata": {},
   "outputs": [],
   "source": [
    "Norte_PH = data.USDxM2[(data.state_name=='Bs.As. G.B.A. Zona Norte') & (data.property_type=='PH')]\n",
    "Norte_PH_min = Norte_PH > (1049.50 * MEN)\n",
    "Norte_PH_max = Norte_PH < (2020.38 * MAY)\n",
    "Norte_PH_fin = Norte_PH_min & Norte_PH_max\n",
    "print(Norte_PH_fin.value_counts())\n",
    "Norte_PH_finT = Norte_PH_fin[Norte_PH_fin==1]\n",
    "Norte_PH_finT.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cap_PH = data.USDxM2[(data.state_name=='Capital Federal') & (data.property_type=='PH')]\n",
    "Cap_PH_min = Cap_PH > (1310.81 * MEN)\n",
    "Cap_PH_max = Cap_PH < (2300.00 * MAY)\n",
    "Cap_PH_fin = Cap_PH_min & Cap_PH_max\n",
    "print(Cap_PH_fin.value_counts())\n",
    "Cap_PH_finT = Cap_PH_fin[Cap_PH_fin==1]\n",
    "Cap_PH_finT.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "Norte_apart = data.USDxM2[(data.state_name=='Bs.As. G.B.A. Zona Norte') & (data.property_type=='apartment')]\n",
    "Norte_apart_min = Norte_apart > (1812.50 * MEN)\n",
    "Norte_apart_max = Norte_apart < (2929.76 * MAY)\n",
    "Norte_apart_fin = Norte_apart_min & Norte_apart_max\n",
    "print(Norte_apart_fin.value_counts())\n",
    "Norte_apart_finT = Norte_apart_fin[Norte_apart_fin==1]\n",
    "Norte_apart_finT.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-reliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cap_apart = data.USDxM2[(data.state_name=='Capital Federal') & (data.property_type=='apartment')]\n",
    "Cap_apart_min = Cap_apart > (2093.02 * MEN)\n",
    "Cap_apart_max = Cap_apart < (3129.30 * MAY)\n",
    "Cap_apart_fin = Cap_apart_min & Cap_apart_max\n",
    "print(Cap_apart_fin.value_counts())\n",
    "Cap_apart_finT = Cap_apart_fin[Cap_apart_fin==1]\n",
    "Cap_apart_finT.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-michael",
   "metadata": {},
   "outputs": [],
   "source": [
    "Norte_house = data.USDxM2[(data.state_name=='Bs.As. G.B.A. Zona Norte') & (data.property_type=='house')]\n",
    "Norte_house_min = Norte_house > (887.37 * MEN)\n",
    "Norte_house_max = Norte_house < (1795.16 * MAY)\n",
    "Norte_house_fin = Norte_house_min & Norte_house_max\n",
    "print(Norte_house_fin.value_counts())\n",
    "Norte_house_finT = Norte_house_fin[Norte_house_fin==1]\n",
    "Norte_house_finT.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-institute",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cap_house = data.USDxM2[(data.state_name=='Capital Federal') & (data.property_type=='house')]\n",
    "Cap_house_min = Cap_house > (935.67 * MEN)\n",
    "Cap_house_max = Cap_house < (2065.05 * MAY)\n",
    "Cap_house_fin = Cap_house_min & Cap_house_max\n",
    "print(Cap_house_fin.value_counts())\n",
    "Cap_house_finT = Cap_house_fin[Cap_house_fin==1]\n",
    "Cap_house_finT.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-judges",
   "metadata": {},
   "outputs": [],
   "source": [
    "Norte_store = data.USDxM2[(data.state_name=='Bs.As. G.B.A. Zona Norte') & (data.property_type=='store')]\n",
    "Norte_store_min = Norte_store > (952.38 * MEN)\n",
    "Norte_store_max = Norte_store < (2608.80 * MAY)\n",
    "Norte_store_fin = Norte_store_min & Norte_store_max\n",
    "print(Norte_store_fin.value_counts())\n",
    "Norte_store_finT = Norte_store_fin[Norte_store_fin==1]\n",
    "Norte_store_finT.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-bullet",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cap_store = data.USDxM2[(data.state_name=='Capital Federal') & (data.property_type=='store')]\n",
    "Cap_store_min = Cap_store > (1595.59 * MEN)\n",
    "Cap_store_max = Cap_store < (4200.41 * MAY)\n",
    "Cap_store_fin = Cap_store_min & Cap_store_max\n",
    "print(Cap_store_fin.value_counts())\n",
    "Cap_store_finT = Cap_store_fin[Cap_store_fin==1]\n",
    "Cap_store_finT.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-beverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "parametro = data.USDxM2[(Norte_PH_finT.index) | (Cap_PH_finT.index) | (Norte_apart_finT.index) | (Cap_apart_finT.index) | (Norte_house_finT.index) | (Cap_house_finT.index) | (Norte_store_finT.index) | (Cap_store_finT.index)]\n",
    "parametro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-former",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = data.loc[parametro.index]\n",
    "data = cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-chancellor",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-twist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos como queda luego de la eliminación de los Outliers\n",
    "sns.set_style('darkgrid')\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.boxplot(data=data.state_name[data.property_type=='house'], x=data.state_name[data.property_type=='house'], y=data.USDxM2)\n",
    "\n",
    "plt.xlabel(\"Provincia\"); plt.ylabel(\"Usd/M2\");plt.title(\"Distribución Dólares por M2 por cada Casas\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-princeton",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.boxplot(data=data.state_name[data.property_type=='store'], x=data.state_name[data.property_type=='store'], y=data.USDxM2)\n",
    "\n",
    "plt.xlabel(\"Provincia\"); plt.ylabel(\"Usd/M2\");plt.title(\"Distribución Dólares por M2 por para Tiendas\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-norwegian",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.boxplot(data=data.state_name[data.property_type=='apartment'], x=data.state_name[data.property_type=='apartment'], y=data.USDxM2)\n",
    "\n",
    "plt.xlabel(\"Provincia\"); plt.ylabel(\"Usd/M2\");plt.title(\"Distribución Dólares por M2 por para Departamentos\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-domain",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.boxplot(data=data.state_name[data.property_type=='PH'], x=data.state_name[data.property_type=='PH'], y=data.USDxM2)\n",
    "\n",
    "plt.xlabel(\"Provincia\"); plt.ylabel(\"Usd/M2\");plt.title(\"Distribución Dólares por M2 por para PH\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.pivot_table(index='state_name', columns='property_type', aggfunc={'USDxM2':'mean', 'price_aprox_usd':'count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-accident",
   "metadata": {},
   "source": [
    "### Análisis de Amenities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-renaissance",
   "metadata": {},
   "source": [
    "##### Búsqueda de Garage en description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "garage_pattern = \"(?P<garage>cochera|garage|estacionamiento)\"\n",
    "garage_regex =  re.compile(garage_pattern)\n",
    "\n",
    "garage_match = data.description.apply(lambda x: x if x is np.NaN else garage_regex.search(x))\n",
    "garage_match_mask = garage_match.notnull()\n",
    "data.loc[garage_match_mask, \"Garage\"] = 1\n",
    "data[\"Garage\"].fillna(0,inplace=True)\n",
    "data.loc[:,\"Garage\"] = data.loc[:,\"Garage\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-mixer",
   "metadata": {},
   "source": [
    "##### Búsqueda de propiedades \"A estrenar\" en description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-philip",
   "metadata": {},
   "outputs": [],
   "source": [
    "estrenar_pattern = \"(?P<estrenar>(a estrenar)|(departamento nuevo))\"\n",
    "estrenar_regex =  re.compile(estrenar_pattern)\n",
    "\n",
    "estrenar_match = data.description.apply(lambda x: x if x is np.NaN else estrenar_regex.search(x))\n",
    "estrenar_match_mask = estrenar_match.notnull()\n",
    "data.loc[estrenar_match_mask, \"Estrenar\"] = 1\n",
    "data[\"Estrenar\"].fillna(0, inplace=True)\n",
    "data.loc[:,\"Estrenar\"] = data.loc[:,\"Estrenar\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-security",
   "metadata": {},
   "source": [
    "##### Búsqueda de Pileta en description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-local",
   "metadata": {},
   "outputs": [],
   "source": [
    "pileta_pattern = \"(?P<pileta>pileta|piscina|picina|pisina)\"\n",
    "pileta_regex =  re.compile(pileta_pattern)\n",
    "\n",
    "pileta_match = data.description.apply(lambda x: x if x is np.NaN else pileta_regex.search(x))\n",
    "pileta_match_mask = pileta_match.notnull()\n",
    "data.loc[pileta_match_mask, \"Pileta\"] = 1\n",
    "data[\"Pileta\"].fillna(0, inplace=True)\n",
    "data.loc[:,\"Pileta\"] = data.loc[:,\"Pileta\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-thousand",
   "metadata": {},
   "source": [
    "##### Búsqueda de Balcón en description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "balcon_pattern = \"(?P<balcon>balcon|balcones|balcón)\"\n",
    "balcon_regex =  re.compile(balcon_pattern)\n",
    "\n",
    "balcon_match = data.description.apply(lambda x: x if x is np.NaN else balcon_regex.search(x))\n",
    "balcon_match_mask = balcon_match.notnull()\n",
    "data.loc[balcon_match_mask, \"Balcon\"] = 1\n",
    "data[\"Balcon\"].fillna(0, inplace=True)\n",
    "data.loc[:,\"Balcon\"] = data.loc[:,\"Balcon\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-malta",
   "metadata": {},
   "source": [
    "##### Búsqueda de Gimnasio en description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-electronics",
   "metadata": {},
   "outputs": [],
   "source": [
    "gym_pattern = \"(?P<gym>gym|gimnasio|gimnacio)\"\n",
    "gym_regex =  re.compile(gym_pattern)\n",
    "\n",
    "gym_match = data.description.apply(lambda x: x if x is np.NaN else gym_regex.search(x))\n",
    "gym_match_mask = gym_match.notnull()\n",
    "data.loc[gym_match_mask, \"Gimnasio\"] = 1\n",
    "data[\"Gimnasio\"].fillna(0, inplace=True)\n",
    "data.loc[:,\"Gimnasio\"] = data.loc[:,\"Gimnasio\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-influence",
   "metadata": {},
   "source": [
    "##### Búsqueda de Quincho en description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-macintosh",
   "metadata": {},
   "outputs": [],
   "source": [
    "quincho_pattern = \"(?P<quincho>quincho|kincho|qincho|(\\ssum\\s))\"\n",
    "quincho_regex =  re.compile(quincho_pattern)\n",
    "\n",
    "quincho_match = data.description.apply(lambda x: x if x is np.NaN else quincho_regex.search(x))\n",
    "quincho_match_mask = quincho_match.notnull()\n",
    "data.loc[quincho_match_mask, \"Quincho\"] = 1\n",
    "data[\"Quincho\"].fillna(0, inplace=True)\n",
    "data.loc[:,\"Quincho\"] = data.loc[:,\"Quincho\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-technology",
   "metadata": {},
   "source": [
    "Tanto Garage como Estrenar van a ser dos columnas separadas\n",
    "\n",
    "La forma es imputación es a traves de variables dummies. Es decir, para cada amenitie agregamos una columna con el nombre de la misma y la completamos con 1 si el anuncio la indica y 0 en caso contrario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-prison",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total de \\\"{0}\\\" imputados: {1}\".format(\"Quincho\", data[\"Quincho\"].sum()))\n",
    "print(\"Total de \\\"{0}\\\" imputados: {1}\".format(\"Gimnasio\", data[\"Gimnasio\"].sum()))\n",
    "print(\"Total de \\\"{0}\\\" imputados: {1}\".format(\"Balcon\", data[\"Balcon\"].sum()))\n",
    "print(\"Total de \\\"{0}\\\" imputados: {1}\".format(\"Pileta\", data[\"Pileta\"].sum()))\n",
    "print(\"Total de \\\"{0}\\\" imputados: {1}\".format(\"Garage\", data[\"Garage\"].sum()))\n",
    "print(\"Total de \\\"{0}\\\" imputados: {1}\".format(\"Estrenar\", data[\"Estrenar\"].sum()))\n",
    "data['Amenities'] = data['Pileta'] + data['Quincho'] + data['Balcon'] + data['Gimnasio']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-syracuse",
   "metadata": {},
   "source": [
    " 1ER CONCLUSION LAS COLUMNAS DE PRICE POR M2 NO SE CONSIDERARAN PORQUE SE GENERARON A PARTIR DE DATOS DE SUPERFICIE Y PRECIO YA LIMPIOS Y ANALIZADOS\n",
    " \n",
    " 3ER CONCLUSION LA COLUMNA ROOMS ES IMPORTANTE PORQUE DA VALOR AL DATASET, SE LLENARÀN LOS NULOS EN LA COLUMNA ROOMS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-tourist",
   "metadata": {},
   "source": [
    "#### Busqueda de Ambientes en title y description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "rooms_pattern = \"\\s(?P<ambientes>\\d\\d?)(\\s?)(?P<sufijo>AMB|amb|Amb)\"\n",
    "rooms_regex =  re.compile(rooms_pattern)\n",
    "\n",
    "rooms_match = data.description.apply(lambda x: x if x is np.NaN else rooms_regex.search(x))\n",
    "rooms_match_mask = rooms_match.notnull()\n",
    "data.loc[rooms_match_mask, \"Ambientes\"] = rooms_match[rooms_match_mask].apply(lambda x: x.group(\"ambientes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Ambientes\"] = data[\"Ambientes\"].astype(float)\n",
    "data.loc[(pd.isnull(data[\"rooms\"])),\"rooms\"] = data[\"Ambientes\"]\n",
    "print('Cantidad rooms null en data inicial:', data[\"rooms\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-cycle",
   "metadata": {},
   "source": [
    "Con el fin de buscar nulos por tipo de propiedad para ver cuanto peso tiene cada nulo por categorìa, generamos una mascara por columna analizada en esta seccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-traveler",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['suptotnulo']= data.surface_total_in_m2.isnull()\n",
    "data['supcubnulo']= data.surface_covered_in_m2.isnull()\n",
    "data['ambnulo']= data.rooms.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aca hago una tabla con nulos discriminado por tipo de propiedad\n",
    "data.groupby(['property_type']).aggregate({'suptotnulo': 'sum', 'supcubnulo': 'sum', 'ambnulo': 'sum'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-continent",
   "metadata": {},
   "source": [
    "ANALISIS A: SUPERFICIE EN RELACION A LOS AMBIENTES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-france",
   "metadata": {},
   "source": [
    "La idea es ver que por ejemplo los 2 ambientes tienen un rango de m2 y los 3 ambientes tambien se encuentran en cierto rango de m2, vamos a ver esa relacion \n",
    "graficando la relacion que hay entre cantidad de ambientes y superficie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-sauce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot.scatter(x='Ambientes',y='m2_calculated', c='DarkBlue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-temple",
   "metadata": {},
   "source": [
    "Conclusion: se pueden sacar outliers de propiedades de mas de 2000 m2 y propiedades de mas de 15 ambientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "#superficie mayor a 10.000m2\n",
    "data = data[data['m2_calculated'] < 2000]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-commander",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hago una mascara para graficar valores de menos de 13 ambientes\n",
    "data = data[data['Ambientes'].fillna(0) <13]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-correlation",
   "metadata": {},
   "source": [
    "CONCLUSION, SE ELIMINAN DEL DATASET OUTLIERS DE INDICES DE MAS DE 15 AMBIENTES Y SUPERFICIES MAYORES A 2000M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax2 = data.plot.scatter(x='Ambientes', y='m2_calculated', c='DarkBlue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"metros1\", \"metros2\", \"metros3\", \"metros4\", \"M2\", \"Pileta\", \"Balcon\", \"Gimnasio\", \n",
    "           \"Quincho\", \"suptotnulo\", \"suptotnulo\", \"supcubnulo\", \"ambnulo\"], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-albuquerque",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Ambientes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-princeton",
   "metadata": {},
   "source": [
    "## CONCLUSIÓN: se genera un nuevo dataset final, el cual se va a exportar para el próximo análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-claim",
   "metadata": {},
   "source": [
    "Primero se eliminan las columnas que no se van a utilizar, se dejan las nuevas columnas que se generaron luego del análisis del dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"operation\", \"country_name\", 'place_with_parent_names',\"geonames_id\", 'lat', 'lon','currency',\n",
    "           'price','price_aprox_local_currency','surface_total_in_m2','surface_covered_in_m2','price_usd_per_m2',\n",
    "           'price_per_m2','rooms'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-concentration",
   "metadata": {},
   "source": [
    "Luego se renombran las columnas, para generar el dataset final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-intent",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'property_type':'Tipo_Propiedad','place_name':'Barrio','state_name':'Región','price_aprox_usd':'Precio','description':'Descripción','title':'Título','m2_calculated':'Metros_cuadrados','USDxM2':'Precio_por_m2','Estrenar':'Estado'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-beaver",
   "metadata": {},
   "source": [
    "Se hace una revisión del nuevo dataset con un \"info\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-vietnam",
   "metadata": {},
   "source": [
    "Finalmente exportamos el dataset para el análisis final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('properati-fase2.csv', sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
